{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages. Using PyTorch by choice\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "#\n",
    "# - Image dimensions (pixel x pixel dimensions). Can also edit channels of input, but usually RGB.\n",
    "#       Final input shape (height, width, 3)\n",
    "#\n",
    "# - Batch size. Number of training samples (images) that will be passed through the NN at once before\n",
    "#       the models internal parameters are updated\n",
    "#\n",
    "# - Data Directories\n",
    "#\n",
    "img_height = 224 # Our images are 64x64, change\n",
    "img_width = 224\n",
    "batch_size = 24\n",
    "train_dir = 'PATH'\n",
    "validation_dir = 'PATH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to load in the dataset. \n",
    "# \n",
    "# As of 1/3/25, I do not know whether or not it will be efficient to load in the full dataset everytime on startup. I assume not. \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to clean the dataset. There will be corrupted images, unwanted stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "#\n",
    "# We use the 'transforms' method of PyTorch to prepare our data for processing\n",
    "#\n",
    "# Random Horizontal Flip reverses each image along vertical axis. This has a couple of upsides:\n",
    "#   - Flipping images effectively doubles training examples w/out new data creation\n",
    "#   - Since GW Lensing is invariant for left/right orientation, flipping helps model generalization\n",
    "#   - General Overfitting prevention (see above point)\n",
    "#\n",
    "# Random Rotation is also used for similar reasons.\n",
    "# \n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "transform_validation = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data & preprocess\n",
    "# \n",
    "# Num_workers refers to the amount of seperate processes used to load data. Ie for 2, the data gets split\n",
    "#   - Increased num_workers can sometimes how downsides, based on various factors such as complexity of \n",
    "#       transformations, hardware being used, etc\n",
    "#   - Of course, less processes also means data loading becomes bottlenecked\n",
    "# \n",
    "# -> An optimal value for num_workers is necessary. A good start is the number of CPU cores\n",
    "#       import psutil\n",
    "#       num_workers = psutil.cpu_count(logical = True/False)\n",
    "#   Where True = # of logical CPU cores and False = physical CPU cores\n",
    "#\n",
    "train_dataset = torchvision.datasets.ImageFolder(root = train_dir, transform = transform_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "\n",
    "validation_dataset = torchvision.datasets.ImageFolder(root = validation_dir, transform = transform_validation)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size = batch_size, shuffle = False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have our dataset ready to be trained on. \n",
    "\n",
    "However, an accurate CNN for image recognition can require up to an image dataset in the millions, for high accuracy. This is simply not feasible for our purposes. There is a better way: Transfer learning. \n",
    "\n",
    "We will perform transfer learning from the ResNet18 CNN model, and learn the weights of the last layer of that model. This will help us efficiently reduce the number of images we need for our dataset, down to around 2,500 - 10,000. \n",
    "\n",
    "The goal will be to do this via creating a CNN with the last set of weights, find the learning rate, and then train our own CNN model. \n",
    "After training we need to tune the Hyper Parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learn from ResNet50 Image recognition\n",
    "#\n",
    "model = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN, modify ResNet\n",
    "# \n",
    "class CNN_Transfer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Transfer).__init__()\n",
    "        self.resnet = torch.hub.load('pytorch/vision', 'resnet18', pretrained = True)\n",
    "        num_classes = 2 # number of classes, subject to change \n",
    "        self.resnet.fc = nn.Linear(pretrained_model.fc.in_features, num_classes) # modifies the final fully connected layer for n classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet\n",
    "\n",
    "model = CNN_Transfer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze Pre-Trained Layers\n",
    "# \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# DO NOT RUN \n",
    "\n",
    "# Create the CNN structure\n",
    "# \n",
    "# CNN class inherits from nn.Module, the base class for all NN in pytorch\n",
    "#\n",
    "# __init__ Initializes all netowrk layers and params\n",
    "#\n",
    "# Forward method defines how data flows through the network layers\n",
    "# \n",
    "# -> For image classification and object detection, convolutional layers are more critical than dense layers.\n",
    "#       - These layers capture and learn spatial heirarchies and extract relecant features\n",
    "#       - More convolutional layers, but not too much since overfitting is a probelm\n",
    "# \n",
    "class CNN(nn.Module): \n",
    "    def __init__(self): # Initializes netowrk layers and params\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,3, padding = 1)# First convolutional layer\n",
    "        # 3 = 3 input channels (RGB). 32 = Number of output channels (filters). 3 = Size of Conv. Kernel (3x3)\n",
    "        # padding 1 = adds 1 pixel border of 0s around input -> keeps output same size as input\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,2) # Maximum Pooling layer\n",
    "        # 2, 2 = size of Window, Stride. Both set to 2x2 -> reduces each dimension by half\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1) # Second Conv. Layer\n",
    "        # input needs to be same size as last output ie 32\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding = 1) # Third Conv. Layer\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512) # First fully connected AKA dense layer\n",
    "        # 128*28*28 = Number of input features, flattened output from conv. layers. \n",
    "        # 512 = Number of output features (neurons)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 2) # Second fully connected Layer\n",
    "        # 512 = input features from previous layer. 2 = output features, for binary classification\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5) # Defines dropout layer\n",
    "        # 0.5 = 50% of neurons will randomly be set to 0 during training -> prevents overfitting\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # Applies first conv. layer, then applies ReLU activation function\n",
    "        # ReLU introduces non-linearity into model -> allows it to learn complex patterns\n",
    "\n",
    "        x = self.pool(F.relu(self.conv2(x))) # Applies second conv. layer\n",
    "        x = self.pool(F.relu(self.conv3(x))) # ^\n",
    "\n",
    "        x = x.view(-1,128*28*28) # Flattens output tensor from Conv. Layers to 1D tensor. This is necessary \n",
    "        # in order to feed it to the dense layers\n",
    "\n",
    "        x = F.relu(self.fc1(x)) # Applies first dense layer, then ReLU activation\n",
    "        x = self.dropout(x) # Applies dropout to output of dense layer\n",
    "        x = self.fc2(x) # Applies second dense layer\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defiine Loss Function, Optimizer\n",
    "#\n",
    "# CrossEntropyLoss uses multiple Log loss functions and combines them into a single class\n",
    "#   - Input: Raw scores from models output layer\n",
    "#   - Target: True class labels\n",
    "#\n",
    "# Optim.Adam -> Adaptive Moment Estimation\n",
    "#   - Model parameters: Method that retuns that returns all params (weights & biases) that need to be \n",
    "#       optimized. Also ensures all learnable params are included in optimization process\n",
    "#   - lr: Learning rate. Hyperparameter, which means we choose. \n",
    "#       Small learning rate -> more precise adjustments, but longer time for convergence\n",
    "#\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001) # Hyperparameter learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "#\n",
    "num_epochs = 25 # Defines how many times Training data is passed through NN\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0 # Keeps track of loss for running epoch\n",
    "\n",
    "    for inputs, labels in train_loader: # Iterates over training data in batches\n",
    "        # Train_Loader provides batches of data from training data set \n",
    "        # Inputs = a batch of input images\n",
    "        # Labels = ground truth labels for input images\n",
    "\n",
    "        optimizer.zero_grad() # clears gradients from last loop\n",
    "\n",
    "        outputs = model(inputs) # Computes model's predictions by performing forward pass through NN\n",
    "\n",
    "        loss = criterion(outputs, labels) # Computes Loss based on prediction\n",
    "        loss.backward() # Computes gradients of loss WRT the model parameters. \"Backward pass\"\n",
    "\n",
    "        optimizer.step() # Updates models parameters using computed gradients, adjusts weights to minimize loss\n",
    "\n",
    "        running_loss += loss.item() # Updates running loss.\n",
    "        # Converts loss tensor to python number, easier for accumulation\n",
    "    \n",
    "    print(f'[Epoch {epoch + 1}, Batch {i+1}] loss: {running_loss/len(train_loader):.3f}')\n",
    "    # prints epoch loss\n",
    "\n",
    "print('Finished Training') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "# \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in validation_loader:\n",
    "        # images, labels = data\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the NN based on validation set: {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
